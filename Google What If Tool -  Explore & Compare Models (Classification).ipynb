{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a884d64",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "> Before deploying a Machine Learning model, it is important to understand the performance of the model\n",
    "\n",
    "> The What-if-tool is a visual interface desgined by Google which helps analyze the machine learning models with minimal lines of code\n",
    "\n",
    "> This Notebook will show you how to use the What-if-tool, we will be using a dataset that is provided for all demos. In this example we will explore how we can use the Google What If Tool in order to measure the performance of a linear classifier model and examine how different features affect the models prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806f33d9",
   "metadata": {},
   "source": [
    "## Required Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72afbc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import functools\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from witwidget.notebook.visualization import WitConfigBuilder\n",
    "from witwidget.notebook.visualization import WitWidget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813fdf80",
   "metadata": {},
   "source": [
    "## Create required definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91665cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a tf feature spec from the dataframe and columns specified.\n",
    "def create_feature_spec(df, columns=None):\n",
    "    feature_spec = {}\n",
    "    if columns == None:\n",
    "        columns = df.columns.values.tolist()\n",
    "    for f in columns:\n",
    "        if df[f].dtype is np.dtype(np.int64):\n",
    "            feature_spec[f] = tf.io.FixedLenFeature(shape=(), dtype=tf.int64)\n",
    "        elif df[f].dtype is np.dtype(np.float64):\n",
    "            feature_spec[f] = tf.io.FixedLenFeature(shape=(), dtype=tf.float32)\n",
    "        else:\n",
    "            feature_spec[f] = tf.io.FixedLenFeature(shape=(), dtype=tf.string)\n",
    "    return feature_spec\n",
    "\n",
    "# Creates simple numeric and categorical feature columns from a feature spec and a\n",
    "# list of columns from that spec to use.\n",
    "#\n",
    "# NOTE: Models might perform better with some feature engineering such as bucketed\n",
    "# numeric columns and hash-bucket/embedding columns for categorical features.\n",
    "def create_feature_columns(columns, feature_spec):\n",
    "    ret = []\n",
    "    for col in columns:\n",
    "        if feature_spec[col].dtype is tf.int64 or feature_spec[col].dtype is tf.float32:\n",
    "            ret.append(tf.feature_column.numeric_column(col))\n",
    "        else:\n",
    "            ret.append(tf.feature_column.indicator_column(\n",
    "                tf.feature_column.categorical_column_with_vocabulary_list(col, list(df[col].unique()))))\n",
    "    return ret\n",
    "\n",
    "# An input function for providing input to a model from tf.Examples\n",
    "def tfexamples_input_fn(examples, feature_spec, label, mode=tf.estimator.ModeKeys.EVAL,\n",
    "                       num_epochs=None, \n",
    "                       batch_size=64):\n",
    "    def ex_generator():\n",
    "        for i in range(len(examples)):\n",
    "            yield examples[i].SerializeToString()\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "      ex_generator, tf.dtypes.string, tf.TensorShape([]))\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        dataset = dataset.shuffle(buffer_size=2 * batch_size + 1)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(lambda tf_example: parse_tf_example(tf_example, label, feature_spec))\n",
    "    dataset = dataset.repeat(num_epochs)\n",
    "    return dataset\n",
    "\n",
    "# Parses Tf.Example protos into features for the input function.\n",
    "def parse_tf_example(example_proto, label, feature_spec):\n",
    "    parsed_features = tf.io.parse_example(serialized=example_proto, features=feature_spec)\n",
    "    target = parsed_features.pop(label)\n",
    "    return parsed_features, target\n",
    "\n",
    "# Converts a dataframe into a list of tf.Example protos.\n",
    "def df_to_examples(df, columns=None):\n",
    "    examples = []\n",
    "    if columns == None:\n",
    "        columns = df.columns.values.tolist()\n",
    "    for index, row in df.iterrows():\n",
    "        example = tf.train.Example()\n",
    "        for col in columns:\n",
    "            if df[col].dtype is np.dtype(np.int64):\n",
    "                example.features.feature[col].int64_list.value.append(int(row[col]))\n",
    "            elif df[col].dtype is np.dtype(np.float64):\n",
    "                example.features.feature[col].float_list.value.append(row[col])\n",
    "            elif row[col] == row[col]:\n",
    "                example.features.feature[col].bytes_list.value.append(row[col].encode('utf-8'))\n",
    "        examples.append(example)\n",
    "    return examples\n",
    "\n",
    "# Converts a dataframe column into a column of 0's and 1's based on the provided test.\n",
    "# Used to force label columns to be numeric for binary classification using a TF estimator.\n",
    "def make_label_column_numeric(df, label_column, test):\n",
    "  df[label_column] = np.where(test(df[label_column]), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb025531",
   "metadata": {},
   "source": [
    "## Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7ec977f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Two_yr_Recidivism</th>\n",
       "      <th>Number_of_Priors</th>\n",
       "      <th>score_factor</th>\n",
       "      <th>Age_Above_FourtyFive</th>\n",
       "      <th>Age_Below_TwentyFive</th>\n",
       "      <th>African_American</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>Native_American</th>\n",
       "      <th>Other</th>\n",
       "      <th>Female</th>\n",
       "      <th>Misdemeanor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6167</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6168</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6169</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6170</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6171</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6172 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Two_yr_Recidivism  Number_of_Priors  score_factor  Age_Above_FourtyFive  \\\n",
       "0                     0                 0             0                     1   \n",
       "1                     1                 0             0                     0   \n",
       "2                     1                 4             0                     0   \n",
       "3                     0                 0             0                     0   \n",
       "4                     1                14             1                     0   \n",
       "...                 ...               ...           ...                   ...   \n",
       "6167                  0                 0             1                     0   \n",
       "6168                  0                 0             0                     0   \n",
       "6169                  0                 0             0                     1   \n",
       "6170                  0                 3             0                     0   \n",
       "6171                  1                 2             0                     0   \n",
       "\n",
       "      Age_Below_TwentyFive  African_American  Asian  Hispanic  \\\n",
       "0                        0                 0      0         0   \n",
       "1                        0                 1      0         0   \n",
       "2                        1                 1      0         0   \n",
       "3                        0                 0      0         0   \n",
       "4                        0                 0      0         0   \n",
       "...                    ...               ...    ...       ...   \n",
       "6167                     1                 1      0         0   \n",
       "6168                     1                 1      0         0   \n",
       "6169                     0                 0      0         0   \n",
       "6170                     0                 1      0         0   \n",
       "6171                     1                 0      0         1   \n",
       "\n",
       "      Native_American  Other  Female  Misdemeanor  \n",
       "0                   0      1       0            0  \n",
       "1                   0      0       0            0  \n",
       "2                   0      0       0            0  \n",
       "3                   0      1       0            1  \n",
       "4                   0      0       0            0  \n",
       "...               ...    ...     ...          ...  \n",
       "6167                0      0       0            0  \n",
       "6168                0      0       0            0  \n",
       "6169                0      1       0            0  \n",
       "6170                0      0       1            1  \n",
       "6171                0      0       1            0  \n",
       "\n",
       "[6172 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path = 'dataset/propublica_data_for_fairml.csv'\n",
    "\n",
    "# Set the column names for the columns in the CSV. If the CSV's first line is a header line containing\n",
    "# the column names, then set this to None. In this example we do not need to define the column names\n",
    "\n",
    "# csv_columns = [\"Two_yr_Recidivism\", \"Number_of_Priors\", \"score_factor\", \"Age_Above_FourtyFive\", \"Age_Below_TwentyFive\", \n",
    "#                \"African_American\", \"Asian\", \"Hispanic\", \"Native_American\", \"Other\", \"Female\", \"Misdemeanor\" ]\n",
    "\n",
    "# Read the dataset from the provided CSV and print out information about it\n",
    "df = pd.read_csv(csv_path, skipinitialspace=True)\n",
    "df\n",
    "\n",
    "# If using csv_columns defined above use the code shown below:\n",
    "# df = pd.read_csv(csv_path, names=csv_columns, skipinitialspace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a1a0d0",
   "metadata": {},
   "source": [
    "## Specify input columns and column to predict\n",
    "> In this example we will try to use our dataset to identify and predict if an individual will have a misdemeanor based on the features / data provided\n",
    "\n",
    "> NOTE: In this example all of our values are already binary (1 & 0). In the case that you wish to use text based values this can be done. However, the column that you are predicting on needs to be binary (1 & 0). If our dataset had text values and a misdemeanor was identified by \"Yes\" or \"No\", we could use the below code example to turn those values into Binary, again, only the field we are predicting on requires binary values.\n",
    "\n",
    "> Example code: make_label_column_numeric(df, label_column, lambda val: val == 'Yes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8c1c674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the column in the dataset you wish for the model to predict\n",
    "\n",
    "label_column = 'Misdemeanor'\n",
    "\n",
    "# Set list of all columns from the dataset we will use for the model input\n",
    "input_features = [\"Two_yr_Recidivism\", \"Number_of_Priors\", \"score_factor\", \"Age_Above_FourtyFive\", \"Age_Below_TwentyFive\", \n",
    "                \"African_American\", \"Asian\", \"Hispanic\", \"Native_American\", \"Other\", \"Female\"]\n",
    "\n",
    "# Create a list containing all input features and the label column\n",
    "features_and_labels = input_features + [label_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c53e615",
   "metadata": {},
   "source": [
    "## Convert dataset to tf.example protos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f03285ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = df_to_examples(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f2c541",
   "metadata": {},
   "source": [
    "## Create and train the linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fed7da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kchp100\\AppData\\Local\\Temp\\ipykernel_1736\\482683857.py:24: numeric_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n",
      "WARNING:tensorflow:From C:\\Users\\kchp100\\AppData\\Local\\Temp\\ipykernel_1736\\4138584162.py:8: LinearClassifierV2.__init__ (from tensorflow_estimator.python.estimator.canned.linear) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From C:\\Users\\kchp100\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\head\\head_utils.py:54: BinaryClassHead.__init__ (from tensorflow_estimator.python.estimator.head.binary_class_head) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From C:\\Users\\kchp100\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\linear.py:944: Estimator.__init__ (from tensorflow_estimator.python.estimator.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From C:\\Users\\kchp100\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1842: RunConfig.__init__ (from tensorflow_estimator.python.estimator.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\kchp100\\AppData\\Local\\Temp\\tmptxmkx01t\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\kchp100\\\\AppData\\\\Local\\\\Temp\\\\tmptxmkx01t', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From C:\\Users\\kchp100\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:385: StopAtStepHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From C:\\Users\\kchp100\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\training_util.py:396: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From C:\\Users\\kchp100\\AppData\\Local\\Temp\\ipykernel_1736\\482683857.py:37: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_types is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From C:\\Users\\kchp100\\AppData\\Local\\Temp\\ipykernel_1736\\482683857.py:37: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From C:\\Users\\kchp100\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\legacy\\ftrl.py:173: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\kchp100\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\model_fn.py:250: EstimatorSpec.__new__ (from tensorflow_estimator.python.estimator.model_fn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From C:\\Users\\kchp100\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1414: NanTensorHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From C:\\Users\\kchp100\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1417: LoggingTensorHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From C:\\Users\\kchp100\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\basic_session_run_hooks.py:232: SecondOrStepTimer.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From C:\\Users\\kchp100\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1454: CheckpointSaverHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "WARNING:tensorflow:From C:\\Users\\kchp100\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\monitored_session.py:579: StepCounterHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From C:\\Users\\kchp100\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\monitored_session.py:586: SummarySaverHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\kchp100\\AppData\\Local\\Temp\\tmptxmkx01t\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "WARNING:tensorflow:From C:\\Users\\kchp100\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\monitored_session.py:1455: SessionRunArgs.__new__ (from tensorflow.python.training.session_run_hook) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From C:\\Users\\kchp100\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\monitored_session.py:1454: SessionRunContext.__init__ (from tensorflow.python.training.session_run_hook) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From C:\\Users\\kchp100\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\monitored_session.py:1474: SessionRunValues.__new__ (from tensorflow.python.training.session_run_hook) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "INFO:tensorflow:loss = 0.6931472, step = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.155\n",
      "INFO:tensorflow:loss = 0.558056, step = 100 (3.688 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.6823\n",
      "INFO:tensorflow:loss = 0.56280184, step = 200 (3.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.9146\n",
      "INFO:tensorflow:loss = 0.65184355, step = 300 (2.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.2876\n",
      "INFO:tensorflow:loss = 0.6953557, step = 400 (2.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.3894\n",
      "INFO:tensorflow:loss = 0.66575015, step = 500 (2.539 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.9131\n",
      "INFO:tensorflow:loss = 0.6295401, step = 600 (2.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.8001\n",
      "INFO:tensorflow:loss = 0.63185656, step = 700 (2.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.3034\n",
      "INFO:tensorflow:loss = 0.6153143, step = 800 (3.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.7253\n",
      "INFO:tensorflow:loss = 0.5769005, step = 900 (2.800 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.3486\n",
      "INFO:tensorflow:loss = 0.567963, step = 1000 (3.091 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.8943\n",
      "INFO:tensorflow:loss = 0.6146172, step = 1100 (2.639 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.7463\n",
      "INFO:tensorflow:loss = 0.6003596, step = 1200 (1.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.0238\n",
      "INFO:tensorflow:loss = 0.6305194, step = 1300 (1.999 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.1359\n",
      "INFO:tensorflow:loss = 0.5616698, step = 1400 (1.883 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.1838\n",
      "INFO:tensorflow:loss = 0.6058359, step = 1500 (2.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.8142\n",
      "INFO:tensorflow:loss = 0.5992599, step = 1600 (2.007 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.1719\n",
      "INFO:tensorflow:loss = 0.63723695, step = 1700 (1.992 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.6692\n",
      "INFO:tensorflow:loss = 0.6471209, step = 1800 (2.588 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.0751\n",
      "INFO:tensorflow:loss = 0.70352274, step = 1900 (2.495 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2000...\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into C:\\Users\\kchp100\\AppData\\Local\\Temp\\tmptxmkx01t\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2000...\n",
      "INFO:tensorflow:Loss for final step: 0.59004337.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.linear.LinearClassifierV2 at 0x27ec4fb92b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_steps = 2000  #@param {type: \"number\"}\n",
    "\n",
    "# Create a feature spec for the classifier\n",
    "feature_spec = create_feature_spec(df, features_and_labels)\n",
    "\n",
    "# Define and train the classifier\n",
    "train_inpf = functools.partial(tfexamples_input_fn, examples, feature_spec, label_column)\n",
    "classifier = tf.estimator.LinearClassifier(\n",
    "    feature_columns=create_feature_columns(input_features, feature_spec))\n",
    "classifier.train(train_inpf, steps=num_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b566c411",
   "metadata": {},
   "source": [
    "## Split our data so that we have train & test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b416e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3a6f78",
   "metadata": {},
   "source": [
    "## Invoke the What-If Tool for test data and the trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13ca9952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_datapoints = 2000  #@param {type: \"number\"}\n",
    "tool_height_in_px = 1000  #@param {type: \"number\"}\n",
    "\n",
    "# Load up the test dataset\n",
    "test_examples = df_to_examples(test_df[0:num_datapoints])\n",
    "\n",
    "# Setup the tool with the test examples and the trained classifier\n",
    "config_builder = WitConfigBuilder(test_examples[0:num_datapoints]).set_estimator_and_feature_spec(\n",
    "    classifier, feature_spec).set_label_vocab(['Will have Misdemeanor', 'Will not have Misdemeanor'])\n",
    "a = WitWidget(config_builder, height=tool_height_in_px)\n",
    "\n",
    "# .set_compare_estimator_and_feature_spec(\n",
    "#     classifier2, feature_spec).set_label_vocab(['Under 50K', 'Over 50K'])\n",
    "# a = WitWidget(config_builder, height=tool_height_in_px)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7877a0be",
   "metadata": {},
   "source": [
    "# Display our WitWidget defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2643e255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1453fd49b1bd48cb9f95c0b09950b0ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "WitWidget(config={'model_type': 'classification', 'label_vocab': ['Will have Misdemeanor', 'Will not have Misd…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e732c6",
   "metadata": {},
   "source": [
    "# Compare models using Google What If Toolkit\n",
    "> We can also use the Google What If Toolkit not on a singular model but on multiple models. We can use the Toolkit in order to compare how two models predict, this can be useful for the selection of a relevant model to a specific use\n",
    "> In the below example we will deploy an additional DNN Classifier model and identify how this compares to our Linear Classifier model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecebe38",
   "metadata": {},
   "source": [
    "## Create and train our DNN Classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7cc45249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\kchp100\\AppData\\Local\\Temp\\tmpesnsmnj5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x224dd4da970>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_steps_2 = 2000\n",
    "classifier2 = tf.estimator.DNNClassifier(\n",
    "    feature_columns=create_feature_columns(input_features, feature_spec),\n",
    "    hidden_units=[128, 64, 32])\n",
    "classifier2.train(train_inpf, steps=num_steps_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13de7914",
   "metadata": {},
   "source": [
    "## Invoke What-If Tool for test data and the trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "305b5b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_datapoints = 2000  #@param {type: \"number\"}\n",
    "tool_height_in_px = 1000  #@param {type: \"number\"}\n",
    "\n",
    "# Load up the test dataset\n",
    "test_examples = df_to_examples(test_df[0:num_datapoints])\n",
    "\n",
    "# Setup the tool with the test examples and the trained classifier\n",
    "config_builder = WitConfigBuilder(test_examples[0:num_datapoints]).set_estimator_and_feature_spec(\n",
    "    classifier, feature_spec).set_compare_estimator_and_feature_spec(\n",
    "    classifier2, feature_spec).set_label_vocab(['Under 50K', 'Over 50K'])\n",
    "a = WitWidget(config_builder, height=tool_height_in_px)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9092f691",
   "metadata": {},
   "source": [
    "# Display our witwidget defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efb52c1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1736\\2167009006.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed57bb3d",
   "metadata": {},
   "source": [
    "#### Exploration ideas\n",
    "\n",
    "- Organize datapoints by setting X-axis scatter to \"inference score 1\" and Y-axis scatter to \"inference score 2\" to see how each datapoint differs in score between the linear model (1) and DNN model (2). Points off the diagonal have differences in results between the two models.\n",
    "  - Are there patterns of which datapoints don't agree between the two models?\n",
    "  - If you set the ground truth feature dropdown in the \"Performance + Fairness\" tab to \"Over-50K\", then you can color or bin the datapoints by \"inference correct 1\" or \"inference correct 2\". Are there patterns of which datapoints are incorrect for model 1? For model 2?\n",
    "\n",
    "- Explore performance of the two models through the confusion matrices in the \"Performance + Fairness\" tab. Which model is best? Train either model for longer and see if you can change this. Are the rates of errors (false positives and false negatives) that the two models make different?\n",
    "  - Click the \"optimize threshold\" button to set the optimal positive classification threshold for each model based on the current cost ratio of 1. How do those thresholds and the resulting confusion matrices differ?\n",
    "    - Change the cost ratio and optimize the threshold again. How does the threshold and performance change on the two models?\n",
    "  - Slice the dataset by features, such as \"sex\" or \"race\". Does either model have more-equal performance between slices?\n",
    "    - Use the threshold optimization buttons to set optimal thresholds based on the different fairness constraints. How does performance between slices differ between the two models. Does one require larger differences in threshold values per slice to achieve the desired constraint?\n",
    "\n",
    "- Looking at the create_feature_columns function in the \"Define helper methods\" cell, categorical features use one-hot encodings in the model. Perhaps change a many-valued categorical feature, such as education to use an embedding layer. Does anything change in the model behavior (can look through partial dependence plots as one way to investigate)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
