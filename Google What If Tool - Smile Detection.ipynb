{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "417bbed8",
   "metadata": {},
   "source": [
    "# Google What If Toolkit - Smile Detection\n",
    "\n",
    "> In this demo we demonstrate the use of what-if-tool for image recognition models. Our task is to predict if a person is smiling or not. We provide a CNN that is trained on a subset of [CelebA dataset](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) and visualize the results on a separate test subset.\n",
    "\n",
    "> Copyright 2019 Google LLC.\n",
    "> SPDX-License-Identifier: Apache-2.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0f5a2a",
   "metadata": {},
   "source": [
    "\n",
    "# Required Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd1e1a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from witwidget.notebook.visualization import WitWidget, WitConfigBuilder\n",
    "from tensorflow.keras.models import load_model\n",
    "from PIL import Image\n",
    "from io import BytesIO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dd1a1c",
   "metadata": {},
   "source": [
    "## Setup required definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d47fc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converts a dataframe into a list of tf.Example protos.\n",
    "# If images_path is specified, it assumes that the dataframe has a special \n",
    "# column \"image_id\" and the path \"images_path/image_id\" points to an image file.\n",
    "# Given this structure, this function loads and processes the images as png byte_lists\n",
    "# into tf.Examples so that they can be shown in WIT. Note that 'image/encoded'\n",
    "# is a reserved field in WIT for encoded image features.\n",
    "def df_to_examples(df, columns=None, images_path=''):\n",
    "  examples = []\n",
    "  if columns == None:\n",
    "    columns = df.columns.values.tolist()\n",
    "  for index, row in df.iterrows():\n",
    "    example = tf.train.Example()\n",
    "    for col in columns:\n",
    "      if df[col].dtype is np.dtype(np.int64):\n",
    "        example.features.feature[col].int64_list.value.append(int(row[col]))\n",
    "      elif df[col].dtype is np.dtype(np.float64):\n",
    "        example.features.feature[col].float_list.value.append(row[col])\n",
    "      elif row[col] == row[col]:\n",
    "        example.features.feature[col].bytes_list.value.append(row[col].encode('utf-8'))\n",
    "    if images_path:\n",
    "      fname = row['image_id']\n",
    "      with open(os.path.join(images_path, fname), 'rb') as f:\n",
    "        im = Image.open(f)\n",
    "        buf = BytesIO()\n",
    "        im.save(buf, format= 'PNG')\n",
    "        im_bytes = buf.getvalue()\n",
    "        example.features.feature['image/encoded'].bytes_list.value.append(im_bytes)\n",
    "    examples.append(example)\n",
    "  return examples\n",
    "\n",
    "# Converts a dataframe column into a column of 0's and 1's based on the provided test.\n",
    "# Used to force label columns to be numeric for binary classification using a TF estimator.\n",
    "def make_label_column_numeric(df, label_column, test):\n",
    "  df[label_column] = np.where(test(df[label_column]), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6be29a",
   "metadata": {},
   "source": [
    "## Load the csv file into pandas dataframe and process it for WIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f13cd94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset/WIT - Smile Detection Dataset/test_subset/celeba/data_test_subset.csv')\n",
    "examples = df_to_examples(data, images_path='dataset/WIT - Smile Detection Dataset/test_subset/celeba/img_test_subset_resized/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dab5b7",
   "metadata": {},
   "source": [
    "## Load Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7d59244",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_model('dataset/WIT - Smile Detection Dataset/smile-colab-model.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2e5f7e",
   "metadata": {},
   "source": [
    "## Definie custom predict function for WIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c64d0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Define the custom predict function for WIT\n",
    "\n",
    "# This function extracts 'image/encoded' field, which is a reserved key for the \n",
    "# feature that contains encoded image byte list. We read this feature into \n",
    "# BytesIO and decode it back to an image using PIL.\n",
    "# The model expects an array of images that are floats in range 0.0 to 1.0 and \n",
    "# outputs a numpy array of (n_samples, n_labels)\n",
    "def custom_predict(examples_to_infer):\n",
    "  def load_byte_img(im_bytes):\n",
    "    buf = BytesIO(im_bytes)\n",
    "    return np.array(Image.open(buf), dtype=np.float64) / 255.\n",
    "\n",
    "  ims = [load_byte_img(ex.features.feature['image/encoded'].bytes_list.value[0]) \n",
    "         for ex in examples_to_infer]\n",
    "  preds = model1.predict(np.array(ims))\n",
    "  return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc62732",
   "metadata": {},
   "source": [
    "## Invoke What-If Tool for the data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f34884e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_datapoints = 250  #@param {type: \"number\"}\n",
    "tool_height_in_px = 700  #@param {type: \"number\"}\n",
    "\n",
    "# Decode an image from tf.example bytestring\n",
    "def decode_image(ex):\n",
    "  im_bytes = ex.features.feature['image/encoded'].bytes_list.value[0]\n",
    "  im = Image.open(BytesIO(im_bytes))\n",
    "  return im\n",
    "\n",
    "# Define the custom distance function that compares the average color of images\n",
    "def image_mean_distance(ex, exs, params):\n",
    "  selected_im = decode_image(ex)\n",
    "  mean_color = np.mean(selected_im, axis=(0,1))\n",
    "  image_distances = [np.linalg.norm(mean_color - np.mean(decode_image(e), axis=(0,1))) for e in exs]\n",
    "  return image_distances\n",
    "\n",
    "# Setup the tool with the test examples and the trained classifier\n",
    "config_builder = WitConfigBuilder(examples[:num_datapoints]).set_custom_predict_fn(\n",
    "    custom_predict).set_custom_distance_fn(image_mean_distance)\n",
    "\n",
    "wv = WitWidget(config_builder, height=tool_height_in_px)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b34f83",
   "metadata": {},
   "source": [
    "# Display widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afeb57cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af3cc2f1342b476998234499512c9d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "WitWidget(config={'model_type': 'classification', 'label_vocab': [], 'are_sequence_examples': False, 'inferencâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 27ms/step\n"
     ]
    }
   ],
   "source": [
    "wv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
